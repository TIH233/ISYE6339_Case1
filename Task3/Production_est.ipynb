{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production Estimation for BotWorld European Supply Chain\n",
    "\n",
    "This notebook estimates the steady production rate that achieves 99% autonomy inventory for the European market.\n",
    "\n",
    "## Task 3.1 Objectives:\n",
    "1. Estimate 99%-robust steady daily production rate for each category cluster\n",
    "2. Calculate prior start days to maintain 12-week (84-day) 99% autonomy\n",
    "\n",
    "### Product Clusters:\n",
    "- **Cluster 1**: Floor Care (F), Kitchen Help (K), Leisure (L)\n",
    "- **Cluster 2**: Safety & Security (S), Wall & Window Care (W), Exterior Care (X)\n",
    "\n",
    "### Key Methodology Update:\n",
    "- Prior start days based on **MAXIMUM** 84-day autonomy requirement across entire year\n",
    "- Accounts for Cyber Week demand surge (typically highest demand period)\n",
    "- Ensures inventory can survive from Jan 1 through the year's critical period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(\"Production Estimation Notebook - Task 3.1\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Constants and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# US Holidays (hard-coded as per requirements)\n",
    "# 11 holidays: New Year's, MLK, Presidents, Memorial, Independence, Labor,\n",
    "# Columbus, Veterans, Thanksgiving, Day after Thanksgiving, Christmas\n",
    "US_HOLIDAYS_PER_YEAR = 11\n",
    "WORKDAYS_PER_YEAR = 365 - US_HOLIDAYS_PER_YEAR  # 354 workdays\n",
    "AUTONOMY_DAYS = 84  # 12 weeks\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Workdays per year: {WORKDAYS_PER_YEAR}\")\n",
    "print(f\"  Autonomy target: {AUTONOMY_DAYS} days (12 weeks)\")\n",
    "print(f\"  Robustness level: 99%\\n\")\n",
    "\n",
    "# US Holidays by month (approximate - for workday counting)\n",
    "# This is a simplified model: ~11 holidays spread across the year\n",
    "HOLIDAY_RATE = US_HOLIDAYS_PER_YEAR / 365  # ~0.03\n",
    "\n",
    "def count_workdays(num_calendar_days):\n",
    "    \"\"\"Estimate workdays from calendar days accounting for holidays\"\"\"\n",
    "    return int(num_calendar_days * (1 - HOLIDAY_RATE))\n",
    "\n",
    "def calendar_days_for_workdays(num_workdays):\n",
    "    \"\"\"Estimate calendar days needed for given workdays\"\"\"\n",
    "    return int(np.ceil(num_workdays / (1 - HOLIDAY_RATE)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Simulation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all simulation batches\n",
    "sim_batches_path = Path('sim_batches')\n",
    "batch_files = sorted(sim_batches_path.glob('batch_*.csv.gz'))\n",
    "\n",
    "print(f\"Found {len(batch_files)} simulation batch files\")\n",
    "print(\"Loading simulation data...\")\n",
    "\n",
    "# Load all batches\n",
    "all_sims = []\n",
    "for batch_file in batch_files:\n",
    "    df = pd.read_csv(batch_file, compression='gzip')\n",
    "    all_sims.append(df)\n",
    "    print(f\"  Loaded {batch_file.name}\")\n",
    "\n",
    "sim_data = pd.concat(all_sims, ignore_index=True)\n",
    "sim_data['date'] = pd.to_datetime(sim_data['date'])\n",
    "sim_data['year'] = sim_data['date'].dt.year\n",
    "\n",
    "print(f\"\\nLoaded {sim_data['sim'].nunique()} simulations\")\n",
    "print(f\"Date range: {sim_data['date'].min()} to {sim_data['date'].max()}\")\n",
    "print(f\"Total rows: {len(sim_data):,}\")\n",
    "print(f\"Models: {sorted(sim_data['model'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Product Cluster Aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cluster mapping\n",
    "def get_cluster(model):\n",
    "    \"\"\"Map product model to cluster\"\"\"\n",
    "    category = model[0]  # First letter indicates category\n",
    "    if category in ['F', 'K', 'L']:\n",
    "        return 'Cluster_1'\n",
    "    elif category in ['S', 'W', 'X']:\n",
    "        return 'Cluster_2'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "# Add cluster column\n",
    "sim_data['cluster'] = sim_data['model'].apply(get_cluster)\n",
    "\n",
    "# Verify cluster assignment\n",
    "print(\"Cluster assignments:\")\n",
    "cluster_models = sim_data.groupby('cluster')['model'].unique()\n",
    "for cluster, models in cluster_models.items():\n",
    "    print(f\"\\n  {cluster}: {sorted(models)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate Annual Demand by Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate daily sales by cluster, year, and simulation\n",
    "print(\"\\nCalculating annual demand statistics by cluster...\")\n",
    "\n",
    "annual_cluster_demand = sim_data.groupby(['sim', 'year', 'cluster'])['sales_units'].sum().reset_index()\n",
    "annual_cluster_demand.columns = ['sim', 'year', 'cluster', 'annual_sales']\n",
    "\n",
    "# Calculate summary statistics across simulations\n",
    "annual_stats = annual_cluster_demand.groupby(['year', 'cluster'])['annual_sales'].agg([\n",
    "    'mean', 'std', 'min', 'max',\n",
    "    ('p01', lambda x: np.percentile(x, 1)),\n",
    "    ('p05', lambda x: np.percentile(x, 5)),\n",
    "    ('p50', lambda x: np.percentile(x, 50)),\n",
    "    ('p95', lambda x: np.percentile(x, 95)),\n",
    "    ('p99', lambda x: np.percentile(x, 99))\n",
    "]).reset_index()\n",
    "\n",
    "print(\"\\nAnnual demand statistics by cluster:\")\n",
    "print(annual_stats.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate 99%-Robust Steady Daily Production Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nCalculating 99%-robust daily production rates...\")\n",
    "print(f\"Using {WORKDAYS_PER_YEAR} workdays per year\\n\")\n",
    "\n",
    "production_rates = []\n",
    "\n",
    "for year in sorted(annual_stats['year'].unique()):\n",
    "    year_data = annual_stats[annual_stats['year'] == year]\n",
    "    \n",
    "    for cluster in ['Cluster_1', 'Cluster_2']:\n",
    "        cluster_data = year_data[year_data['cluster'] == cluster]\n",
    "        \n",
    "        if len(cluster_data) > 0:\n",
    "            # Use 99th percentile for 99% robustness\n",
    "            annual_demand_p99 = cluster_data['p99'].values[0]\n",
    "            annual_demand_mean = cluster_data['mean'].values[0]\n",
    "            \n",
    "            # Calculate daily production rate\n",
    "            daily_rate_robust = annual_demand_p99 / WORKDAYS_PER_YEAR\n",
    "            daily_rate_mean = annual_demand_mean / WORKDAYS_PER_YEAR\n",
    "            \n",
    "            production_rates.append({\n",
    "                'year': year,\n",
    "                'cluster': cluster,\n",
    "                'annual_demand_mean': annual_demand_mean,\n",
    "                'annual_demand_p99': annual_demand_p99,\n",
    "                'daily_production_mean': daily_rate_mean,\n",
    "                'daily_production_99robust': daily_rate_robust,\n",
    "                'robustness_buffer_pct': ((annual_demand_p99 / annual_demand_mean) - 1) * 100\n",
    "            })\n",
    "\n",
    "production_rates_df = pd.DataFrame(production_rates)\n",
    "\n",
    "print(\"99%-Robust Steady Daily Production Rates:\")\n",
    "print(\"=\"*100)\n",
    "print(production_rates_df.to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "production_rates_df.to_csv('cluster_production_rates.csv', index=False)\n",
    "print(\"\\n‚úì Production rates saved to cluster_production_rates.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calculate Daily Demand and Aggregate by Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nAggregating daily sales by cluster...\")\n",
    "\n",
    "# Aggregate daily sales by cluster across simulations\n",
    "daily_cluster_sales = sim_data.groupby(['sim', 'date', 'cluster'])['sales_units'].sum().reset_index()\n",
    "\n",
    "print(f\"Created daily cluster sales aggregation: {len(daily_cluster_sales):,} rows\")\n",
    "print(f\"Date range: {daily_cluster_sales['date'].min()} to {daily_cluster_sales['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Calculate 84-Day Rolling Autonomy Requirements (CORRECTED)\n",
    "\n",
    "**Key Change**: Calculate autonomy for ALL dates in the year to find the maximum requirement.\n",
    "\n",
    "This accounts for Cyber Week surge and other demand peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCalculating 84-day rolling autonomy requirements...\")\n",
    "print(\"This will identify the maximum autonomy stress point in each year.\\n\")\n",
    "\n",
    "autonomy_requirements = []\n",
    "\n",
    "for cluster in ['Cluster_1', 'Cluster_2']:\n",
    "    print(f\"Processing {cluster}...\")\n",
    "    cluster_data = daily_cluster_sales[daily_cluster_sales['cluster'] == cluster].copy()\n",
    "    \n",
    "    for sim in sorted(cluster_data['sim'].unique()):\n",
    "        sim_data_cluster = cluster_data[cluster_data['sim'] == sim].sort_values('date').copy()\n",
    "        \n",
    "        # Calculate rolling 84-day FORWARD cumulative sum\n",
    "        sim_data_cluster = sim_data_cluster.set_index('date')\n",
    "        \n",
    "        # Forward-looking: sum of next 84 days\n",
    "        sim_data_cluster['future_84day_demand'] = (\n",
    "            sim_data_cluster['sales_units']\n",
    "            .rolling(window=AUTONOMY_DAYS, min_periods=1)\n",
    "            .sum()\n",
    "            .shift(-AUTONOMY_DAYS + 1)\n",
    "        )\n",
    "        \n",
    "        sim_data_cluster = sim_data_cluster.reset_index()\n",
    "        autonomy_requirements.append(\n",
    "            sim_data_cluster[['sim', 'date', 'cluster', 'future_84day_demand']]\n",
    "        )\n",
    "    \n",
    "    print(f\"  ‚úì Completed {cluster}\")\n",
    "\n",
    "autonomy_df = pd.concat(autonomy_requirements, ignore_index=True)\n",
    "autonomy_df = autonomy_df.dropna(subset=['future_84day_demand'])\n",
    "\n",
    "print(f\"\\nTotal autonomy data points: {len(autonomy_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 99th percentile of 84-day demand for each date and cluster\n",
    "print(\"\\nCalculating P99 autonomy requirements for each date...\")\n",
    "\n",
    "autonomy_p99 = autonomy_df.groupby(['date', 'cluster'])['future_84day_demand'].agg(\n",
    "    lambda x: np.percentile(x, 99)\n",
    ").reset_index()\n",
    "autonomy_p99.columns = ['date', 'cluster', 'autonomy_inventory_p99']\n",
    "autonomy_p99['date'] = pd.to_datetime(autonomy_p99['date'])\n",
    "autonomy_p99['year'] = autonomy_p99['date'].dt.year\n",
    "autonomy_p99['day_of_year'] = autonomy_p99['date'].dt.dayofyear\n",
    "\n",
    "print(f\"Autonomy P99 data points: {len(autonomy_p99):,}\")\n",
    "print(f\"\\nSample of 12-week 99% autonomy requirements:\")\n",
    "print(autonomy_p99.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate Prior Start Days (CORRECTED ALGORITHM)\n",
    "\n",
    "**New Methodology**:\n",
    "1. Find the **maximum** 84-day autonomy requirement across the entire year (likely before Cyber Week)\n",
    "2. Calculate cumulative net production from Jan 1 to that critical date\n",
    "3. Determine required inventory on Jan 1 to survive until critical date with sufficient autonomy\n",
    "4. Calculate prior start days to build that Jan 1 inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"CALCULATING PRIOR START DAYS - CORRECTED ALGORITHM\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "prior_start_days = []\n",
    "\n",
    "for year in range(2027, 2035):\n",
    "    jan1 = pd.Timestamp(f'{year}-01-01')\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Year {year}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for cluster in ['Cluster_1', 'Cluster_2']:\n",
    "        print(f\"\\n  {cluster}:\")\n",
    "        \n",
    "        # STEP 1: Find critical date with maximum autonomy requirement\n",
    "        year_autonomy = autonomy_p99[\n",
    "            (autonomy_p99['year'] == year) & \n",
    "            (autonomy_p99['cluster'] == cluster)\n",
    "        ].copy()\n",
    "        \n",
    "        if len(year_autonomy) == 0:\n",
    "            print(\"    ‚ö† No data for this year/cluster\")\n",
    "            continue\n",
    "        \n",
    "        # Find maximum autonomy requirement\n",
    "        max_idx = year_autonomy['autonomy_inventory_p99'].idxmax()\n",
    "        critical_date = year_autonomy.loc[max_idx, 'date']\n",
    "        max_autonomy = year_autonomy.loc[max_idx, 'autonomy_inventory_p99']\n",
    "        critical_day_of_year = year_autonomy.loc[max_idx, 'day_of_year']\n",
    "        \n",
    "        print(f\"    Critical date: {critical_date.strftime('%Y-%m-%d')} (day {critical_day_of_year})\")\n",
    "        print(f\"    Max 84-day autonomy required: {max_autonomy:,.2f} units\")\n",
    "        \n",
    "        # STEP 2: Calculate cumulative net production from Jan 1 to critical date\n",
    "        days_jan1_to_critical = (critical_date - jan1).days\n",
    "        workdays_to_critical = count_workdays(days_jan1_to_critical)\n",
    "        \n",
    "        # Get daily production rate for this year/cluster\n",
    "        prod_rate = production_rates_df[\n",
    "            (production_rates_df['year'] == year) & \n",
    "            (production_rates_df['cluster'] == cluster)\n",
    "        ]\n",
    "        \n",
    "        if len(prod_rate) == 0:\n",
    "            print(\"    ‚ö† No production rate data\")\n",
    "            continue\n",
    "        \n",
    "        daily_production = prod_rate['daily_production_99robust'].values[0]\n",
    "        cumulative_production = daily_production * workdays_to_critical\n",
    "        \n",
    "        print(f\"    Days Jan1‚ÜíCritical: {days_jan1_to_critical} ({workdays_to_critical} workdays)\")\n",
    "        print(f\"    Cumulative production: {cumulative_production:,.2f} units\")\n",
    "        \n",
    "        # Calculate cumulative demand P99 from Jan 1 to critical date\n",
    "        jan1_to_critical_demands = []\n",
    "        for sim in sorted(daily_cluster_sales['sim'].unique()):\n",
    "            sim_cluster_data = daily_cluster_sales[\n",
    "                (daily_cluster_sales['sim'] == sim) &\n",
    "                (daily_cluster_sales['cluster'] == cluster) &\n",
    "                (daily_cluster_sales['date'] >= jan1) &\n",
    "                (daily_cluster_sales['date'] <= critical_date)\n",
    "            ]\n",
    "            demand_sum = sim_cluster_data['sales_units'].sum()\n",
    "            jan1_to_critical_demands.append(demand_sum)\n",
    "        \n",
    "        cumulative_demand_p99 = np.percentile(jan1_to_critical_demands, 99)\n",
    "        cumulative_net = cumulative_production - cumulative_demand_p99\n",
    "        \n",
    "        print(f\"    Cumulative demand P99: {cumulative_demand_p99:,.2f} units\")\n",
    "        print(f\"    Net accumulation: {cumulative_net:,.2f} units\")\n",
    "        \n",
    "        # STEP 3: Calculate required inventory on Jan 1\n",
    "        required_inventory_jan1 = max_autonomy - cumulative_net\n",
    "        \n",
    "        print(f\"    Required inventory on Jan1: {required_inventory_jan1:,.2f} units\")\n",
    "        \n",
    "        # STEP 4: Calculate prior start days\n",
    "        workdays_needed = required_inventory_jan1 / daily_production\n",
    "        prior_calendar_days = calendar_days_for_workdays(workdays_needed)\n",
    "        start_date = jan1 - pd.Timedelta(days=prior_calendar_days)\n",
    "        \n",
    "        print(f\"    Workdays needed: {workdays_needed:.1f}\")\n",
    "        print(f\"    Prior start days: {prior_calendar_days} calendar days\")\n",
    "        print(f\"    Production start date: {start_date.strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "        prior_start_days.append({\n",
    "            'year': year,\n",
    "            'cluster': cluster,\n",
    "            'critical_date': critical_date,\n",
    "            'critical_day_of_year': critical_day_of_year,\n",
    "            'max_autonomy_required': max_autonomy,\n",
    "            'days_jan1_to_critical': days_jan1_to_critical,\n",
    "            'workdays_jan1_to_critical': workdays_to_critical,\n",
    "            'cumulative_production_jan1_to_critical': cumulative_production,\n",
    "            'cumulative_demand_p99_jan1_to_critical': cumulative_demand_p99,\n",
    "            'net_accumulation_jan1_to_critical': cumulative_net,\n",
    "            'required_inventory_jan1': required_inventory_jan1,\n",
    "            'daily_production_rate': daily_production,\n",
    "            'workdays_needed_for_prior': workdays_needed,\n",
    "            'prior_start_days': prior_calendar_days,\n",
    "            'production_start_date': start_date\n",
    "        })\n",
    "\n",
    "prior_start_df = pd.DataFrame(prior_start_days)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"PRIOR START DAYS SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "print(prior_start_df[[\n",
    "    'year', 'cluster', 'critical_date', 'max_autonomy_required',\n",
    "    'required_inventory_jan1', 'prior_start_days', 'production_start_date'\n",
    "]].to_string(index=False))\n",
    "\n",
    "# Save to CSV\n",
    "prior_start_df.to_csv('prior_start_days_corrected.csv', index=False)\n",
    "print(\"\\n‚úì Prior start days saved to prior_start_days_corrected.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 1: Daily Production Rates\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "for idx, cluster in enumerate(['Cluster_1', 'Cluster_2']):\n",
    "    cluster_prod = production_rates_df[production_rates_df['cluster'] == cluster]\n",
    "    \n",
    "    axes[idx].plot(cluster_prod['year'], cluster_prod['daily_production_mean'], \n",
    "                   marker='o', label='Mean Demand', linewidth=2)\n",
    "    axes[idx].plot(cluster_prod['year'], cluster_prod['daily_production_99robust'], \n",
    "                   marker='s', label='99% Robust', linewidth=2)\n",
    "    \n",
    "    axes[idx].set_xlabel('Year', fontsize=12)\n",
    "    axes[idx].set_ylabel('Daily Production Rate (units)', fontsize=12)\n",
    "    axes[idx].set_title(f'{cluster} Daily Production Rates', fontsize=14, fontweight='bold')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('daily_production_rates.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úì Saved daily_production_rates.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2: Prior Start Days\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "years = sorted(prior_start_df['year'].unique())\n",
    "x = np.arange(len(years))\n",
    "width = 0.35\n",
    "\n",
    "cluster1_data = prior_start_df[prior_start_df['cluster'] == 'Cluster_1'].sort_values('year')\n",
    "cluster2_data = prior_start_df[prior_start_df['cluster'] == 'Cluster_2'].sort_values('year')\n",
    "\n",
    "ax.bar(x - width/2, cluster1_data['prior_start_days'], width, \n",
    "       label='Cluster 1 (F, K, L)', alpha=0.8, color='steelblue')\n",
    "ax.bar(x + width/2, cluster2_data['prior_start_days'], width, \n",
    "       label='Cluster 2 (S, W, X)', alpha=0.8, color='coral')\n",
    "\n",
    "ax.set_xlabel('Year', fontsize=12)\n",
    "ax.set_ylabel('Prior Start Days (Calendar Days)', fontsize=12)\n",
    "ax.set_title('Days to Start Production Before Year Begin (Corrected Algorithm)\\n'\n",
    "             'Based on Maximum 84-Day Autonomy Requirement', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(years)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('prior_start_days_corrected.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úì Saved prior_start_days_corrected.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 3: Critical Dates Analysis\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "for idx, cluster in enumerate(['Cluster_1', 'Cluster_2']):\n",
    "    cluster_prior = prior_start_df[prior_start_df['cluster'] == cluster].sort_values('year')\n",
    "    \n",
    "    axes[idx].scatter(cluster_prior['year'], cluster_prior['critical_day_of_year'],\n",
    "                     s=cluster_prior['max_autonomy_required']/50, alpha=0.6, c='red')\n",
    "    \n",
    "    axes[idx].set_xlabel('Year', fontsize=12)\n",
    "    axes[idx].set_ylabel('Day of Year', fontsize=12)\n",
    "    axes[idx].set_title(f'{cluster} - Critical Date (Max Autonomy Required)\\n'\n",
    "                       'Size = Max Autonomy Requirement', \n",
    "                       fontsize=14, fontweight='bold')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    axes[idx].axhline(y=330, color='orange', linestyle='--', alpha=0.5, label='~Cyber Week (day 330)')\n",
    "    axes[idx].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('critical_dates_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úì Saved critical_dates_analysis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 4: Autonomy Requirements Over Time (2027 example)\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "year_to_plot = 2027\n",
    "autonomy_year = autonomy_p99[autonomy_p99['year'] == year_to_plot]\n",
    "\n",
    "for idx, cluster in enumerate(['Cluster_1', 'Cluster_2']):\n",
    "    cluster_autonomy = autonomy_year[autonomy_year['cluster'] == cluster].sort_values('date')\n",
    "    \n",
    "    axes[idx].plot(cluster_autonomy['date'], cluster_autonomy['autonomy_inventory_p99'], \n",
    "                   linewidth=2, color='darkblue', label='84-day autonomy P99')\n",
    "    \n",
    "    # Mark critical date\n",
    "    cluster_critical = prior_start_df[\n",
    "        (prior_start_df['year'] == year_to_plot) & \n",
    "        (prior_start_df['cluster'] == cluster)\n",
    "    ]\n",
    "    if len(cluster_critical) > 0:\n",
    "        critical_date = cluster_critical['critical_date'].values[0]\n",
    "        max_autonomy = cluster_critical['max_autonomy_required'].values[0]\n",
    "        axes[idx].axvline(x=critical_date, color='red', linestyle='--', \n",
    "                         label=f'Critical date: {pd.Timestamp(critical_date).strftime(\"%Y-%m-%d\")}')\n",
    "        axes[idx].scatter([critical_date], [max_autonomy], s=200, c='red', zorder=5)\n",
    "    \n",
    "    axes[idx].axhline(y=cluster_autonomy['autonomy_inventory_p99'].mean(), \n",
    "                      color='green', linestyle=':', alpha=0.5, label='Average')\n",
    "    \n",
    "    axes[idx].set_xlabel('Date', fontsize=12)\n",
    "    axes[idx].set_ylabel('Inventory Required (units)', fontsize=12)\n",
    "    axes[idx].set_title(f'{cluster} - 12-Week 99% Autonomy Requirement ({year_to_plot})', \n",
    "                        fontsize=14, fontweight='bold')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('autonomy_inventory_2027_corrected.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úì Saved autonomy_inventory_2027_corrected.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"TASK 3.1 SUMMARY: PRODUCTION PLANNING FOR 99% AUTONOMY (CORRECTED)\")\n",
    "print(\"=\"*120)\n",
    "print(\"\\nüìä KEY FINDINGS:\\n\")\n",
    "\n",
    "print(\"1. METHODOLOGY CORRECTION\")\n",
    "print(\"   ‚úì Prior start days now based on MAXIMUM 84-day autonomy across entire year\")\n",
    "print(\"   ‚úì Accounts for Cyber Week and other demand surges\")\n",
    "print(\"   ‚úì Ensures inventory sufficiency from Jan 1 through critical peak period\\n\")\n",
    "\n",
    "print(\"2. STEADY DAILY PRODUCTION RATES (99%-Robust)\\n\")\n",
    "print(\"   Cluster 1 (Floor Care, Kitchen Help, Leisure):\")\n",
    "cluster1_summary = production_rates_df[production_rates_df['cluster'] == 'Cluster_1']\n",
    "for _, row in cluster1_summary.head(3).iterrows():\n",
    "    print(f\"   - {int(row['year'])}: {row['daily_production_99robust']:.2f} units/day\")\n",
    "\n",
    "print(\"\\n   Cluster 2 (Safety & Security, Wall & Window Care, Exterior Care):\")\n",
    "cluster2_summary = production_rates_df[production_rates_df['cluster'] == 'Cluster_2']\n",
    "for _, row in cluster2_summary.head(3).iterrows():\n",
    "    print(f\"   - {int(row['year'])}: {row['daily_production_99robust']:.2f} units/day\")\n",
    "\n",
    "print(\"\\n3. PRIOR START DAYS (Based on Maximum Autonomy Requirement)\\n\")\n",
    "print(\"   Cluster 1:\")\n",
    "cluster1_prior = prior_start_df[prior_start_df['cluster'] == 'Cluster_1']\n",
    "for _, row in cluster1_prior.head(3).iterrows():\n",
    "    print(f\"   - {int(row['year'])}: Start {int(row['prior_start_days'])} days before Jan 1 \"\n",
    "          f\"(Critical date: {pd.Timestamp(row['critical_date']).strftime('%b %d')})\")\n",
    "\n",
    "print(\"\\n   Cluster 2:\")\n",
    "cluster2_prior = prior_start_df[prior_start_df['cluster'] == 'Cluster_2']\n",
    "for _, row in cluster2_prior.head(3).iterrows():\n",
    "    print(f\"   - {int(row['year'])}: Start {int(row['prior_start_days'])} days before Jan 1 \"\n",
    "          f\"(Critical date: {pd.Timestamp(row['critical_date']).strftime('%b %d')})\")\n",
    "\n",
    "print(\"\\n4. CRITICAL DATES (Where Maximum Autonomy is Required)\\n\")\n",
    "avg_critical_day = prior_start_df['critical_day_of_year'].mean()\n",
    "print(f\"   Average critical day of year: {avg_critical_day:.0f} (~{pd.Timestamp('2027-01-01') + pd.Timedelta(days=int(avg_critical_day)):%B %d})\")\n",
    "print(\"   Note: Typically aligns with pre-Cyber Week period (late November)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"\\n‚úì Analysis complete. Output files generated:\")\n",
    "print(\"  - cluster_production_rates.csv\")\n",
    "print(\"  - prior_start_days_corrected.csv\")\n",
    "print(\"  - daily_production_rates.png\")\n",
    "print(\"  - prior_start_days_corrected.png\")\n",
    "print(\"  - critical_dates_analysis.png\")\n",
    "print(\"  - autonomy_inventory_2027_corrected.png\")\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(\"\\n‚ö†Ô∏è  NEXT STEP: Run Task 3.2 simulator (Production_feasibility_simulator.ipynb)\")\n",
    "print(\"   to validate these production plans achieve 99% autonomy!\")\n",
    "print(\"=\"*120)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
